# MIPRO (Multi-Instruction Prompt Optimization) Configuration
#
# MIPRO uses Bayesian optimization to find optimal:
# - Instructions (system prompts)
# - Few-shot demonstrations (examples)
# - Instruction variants for each module
#
# Best for:
# - Instruction-following tasks
# - Tasks with clear input/output structure
# - When you want faster convergence

[prompt_learning]
algorithm = "mipro"
task_app_url = "http://localhost:8001"
task_app_id = "banking77"

# Policy: Model for generating responses
[prompt_learning.policy]
model = "openai/gpt-oss-20b"
provider = "groq"
temperature = 0.0
max_completion_tokens = 128
policy_name = "banking77-mipro"

# Initial prompt template
[prompt_learning.initial_prompt]
id = "baseline_v1"
name = "Baseline Prompt"

[[prompt_learning.initial_prompt.messages]]
role = "system"
pattern = "You are a classification assistant."

[[prompt_learning.initial_prompt.messages]]
role = "user"
pattern = "Classify: {input}"

[prompt_learning.initial_prompt.wildcards]
input = "REQUIRED"

# MIPRO Configuration
[prompt_learning.mipro]
env_name = "banking77"
num_iterations = 16
num_evaluations_per_iteration = 6
batch_size = 6
max_concurrent = 16
few_shot_score_threshold = 0.85
proposer_effort = "LOW"
proposer_output_tokens = "FAST"

# Seed pools - using range notation
bootstrap_train_seeds = { start = 0, end = 5 }
online_pool = { start = 5, end = 15 }
test_pool = { start = 15, end = 20 }
reference_pool = { start = 20, end = 25 }

# Token limits
max_token_limit = 100000
max_spend_usd = 5.0
