[prompt_learning]
algorithm = "gepa"
task_app_url = "http://127.0.0.1:8120"  # Will be overridden by InProcessTaskApp
task_app_api_key = "${ENVIRONMENT_API_KEY}"
env_file_path = "../../../.env"
results_folder = "results"

[prompt_learning.initial_prompt]
id = "banking77_pattern"
name = "Banking77 Intent Classification Pattern"

[[prompt_learning.initial_prompt.messages]]
role = "system"
pattern = "You are an expert banking assistant that classifies customer queries into banking intents. Given a customer message, respond with exactly one intent label from the provided list using the `banking77_classify` tool."
order = 0

[[prompt_learning.initial_prompt.messages]]
role = "user"
pattern = "Customer Query: {query}\n\nAvailable Intents:\n{available_intents}\n\nClassify this query into one of the above banking intents using the tool call."
order = 1

[prompt_learning.initial_prompt.wildcards]
query = "REQUIRED"
available_intents = "REQUIRED"

[prompt_learning.policy]
inference_mode = "synth_hosted"
model = "gpt-4.1-nano"
provider = "openai"
temperature = 0.0
max_completion_tokens = 64

[prompt_learning.gepa]
env_name = "banking77"
proposer_effort = "MEDIUM"
proposer_output_tokens = "FAST"
dspy_temperature = 1.0
synth_temperature = 1.0
gepa_ai_temperature = 1.0

[prompt_learning.gepa.evaluation]
# Large pareto set: 100 seeds for pareto scoring
# Large validation: 200 seeds for validation
# Total train: 120 seeds (100 for pareto, 20 for feedback)
train_seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]
val_seeds = [200, 202, 204, 206, 208, 210, 212, 214, 216, 218, 220, 222, 224, 226, 228, 230, 232, 234, 236, 238, 240, 242, 244, 246, 248, 250, 252, 254, 256, 258, 260, 262, 264, 266, 268, 270, 272, 274, 276, 278, 280, 282, 284, 286, 288, 290, 292, 294, 296, 298, 300, 302, 304, 306, 308, 310, 312, 314, 316, 318, 320, 322, 324, 326, 328, 330, 332, 334, 336, 338, 340, 342, 344, 346, 348, 350, 352, 354, 356, 358, 360, 362, 364, 366, 368, 370, 372, 374, 376, 378, 380, 382, 384, 386, 388, 390, 392, 394, 396, 398, 400, 402, 404, 406, 408, 410, 412, 414, 416, 418, 420, 422, 424, 426, 428, 430, 432, 434, 436, 438, 440, 442, 444, 446, 448, 450, 452, 454, 456, 458, 460, 462, 464, 466, 468, 470, 472, 474, 476, 478, 480, 482, 484, 486, 488, 490, 492, 494, 496, 498, 500, 502, 504, 506, 508, 510, 512, 514, 516, 518, 520, 522, 524, 526, 528, 530, 532, 534, 536, 538, 540, 542, 544, 546, 548, 550, 552, 554, 556, 558, 560, 562, 564, 566, 568, 570, 572, 574, 576, 578, 580, 582, 584, 586, 588, 590, 592, 594, 596, 598]
validation_pool = "train"
validation_top_k = 10  # Evaluate top 10 candidates on validation set

[prompt_learning.gepa.rollout]
budget = 500  # Enough rollouts to get 15 candidates
max_concurrent = 200
minibatch_size = 3

[prompt_learning.gepa.mutation]
rate = 0.3
llm_model = "gpt-5-mini"
llm_provider = "openai"
llm_inference_url = "https://api.openai.com/v1"
temperature = 1.0
max_tokens = 8192

[prompt_learning.gepa.population]
initial_size = 12
num_generations = 20  # Enough generations to get 20+ candidates
children_per_generation = 6

[prompt_learning.gepa.archive]
max_size = 20  # Keep 20 candidates in archive
pareto_set_size = 40  # 40 seeds for pareto scoring
min_score_threshold = 0.0
feedback_fraction = 0.667  # 80/120 = 0.667 feedback fraction (80 seeds for feedback, 40 for pareto)

[prompt_learning.gepa.token]
max_limit = 4096
counting_model = "gpt-4"
enforce_limit = false

[prompt_learning.termination_config]
max_cost_usd = 20.0
max_trials = 300  # Enough trials to get 15 candidates (12 + 16*6 = 108 max, so 300 gives headroom)

[display]
local_backend = true
tui = false
show_curve = true
verbose_summary = true
show_trial_results = true
show_transformations = false
show_validation = true
